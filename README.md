
# Apache Nifi

## What is Apache Nifi
```xml 
Apache NiFi is an open-source, visual data integration platform that automates 
the flow of data between systems, allowing users to design, control, and 
monitor data pipelines through a user-friendly, web-based interface, 
supporting batch and real-time scenarios with features like data provenance, 
security, and scalability. Originally developed by the NSA, it provides a flow-based 
programming model to move, transform, and route data efficiently, acting as a 
powerful tool for data engineering and pipeline automation. 

Key Terms:
Data flow: Moving data from source to destination. Data can be of any format 
like csv, json, xml, http data, image, videoes, telemetry etc
Data Pipeline: Movement and transformation of data content from source to destination 
ETL: Extract, Transform, Load


Key Features
Web UI: A visual interface to build data flows by connecting processors (components).
Data Provenance: Tracks every piece of data (FlowFile) from its origin to its destination, 
showing lineage and history.
Data Flow Automation: Automates data movement, ingestion, enrichment, and transformation 
between diverse sources and destinations.
Flow-Based Programming: Uses a visual, diagrammatic approach to define data pipelines.
Guaranteed Delivery: Configurable to be loss-tolerant or guarantee delivery, with priority queuing.
Extensible: Allows developers to create custom processors and services.
Secure & Scalable: Supports multi-tenant security and clustering for large-scale deployments. 

How it Works (Core Concepts)
FlowFile: The fundamental unit of data in NiFi, containing the actual data (content) 
and metadata (attributes).
Processor: Individual components that perform specific tasks (e.g., fetching data, 
transforming, routing).
Connection: The path data flows along between processors, often with backpressure to 
manage data flow rates.
FlowFile Repository, Content Repository, Provenance Repository: Key components for 
managing FlowFile state, content, and history. 

Use Cases
Collecting data from logs, sensors, and applications.
Real-time data streaming and processing.
Data integration for Big Data systems (e.g., Kafka, Hadoop).
Cybersecurity, observability, and generative AI data pipelines. 

Why choose a framework? (4Vs)
Volume, Velocity, Variety, Veracity (messiness and trustworthiness)

```
![alt text](https://github.com/balaji1974/apache-nifi/blob/main/Nifi-Core.png)

## Installing Nifi on Mac
```xml 
1. Download Nifi
https://nifi.apache.org/download/
Download the binary version
and unzip and move to your the folder of your choice

2. Start Nifi
Go the folder Nifi base folder and run the command
./bin/nifi.sh start
tail -f ./logs/nifi-app.log

3. Set Password
The default user name and password can be viewed on the log file
at /logs/nifi-app.log
Search for the lines Generated Username
In my case I have this:
Generated Username [***username***]
Generated Password [***password***]
* this is generated only once during first run 
and must be changed. 

You can change the password by using the below comm
./bin/nifi.sh set-single-user-credentials USERNAME PASSWORD

Stop Nifi
./bin/nifi.sh stop

and Start it back 
./bin/nifi.sh start


4. Go to Nifi console
https://localhost:8080/nifi
Login using the user id and password

5. Stop Nifi
./bin/nifi.sh stop

```

## First Nifi Process - Copy Files
```xml 
1. Drag a Processer
2. Search for getFile
3. Click on the properties -> Input directory 
4. Enter a source folder path 

5. Drag another Processer
6. Search for putFile
7. Click on the properties -> Directory 
8. Enter a destination folder path 
9. Relationship Tab
10. Failure -> Terminate
11. Success -> Terminate

12. Pull the arrow (connection) from Input Processor to 
Output Processor
13. Start both processes by righ click + start

14. Put any file on the source folder and its 
immediately copied to the destination folder

Import template named GetAndPut.xml into your project 
and drag it to your canvas to see it working

```

## Core Nifi Terminologies
```xml 
What is Nifi? 
Nifi consist of automic elements which can be combibed to groups
to build a data flow
Nifi consiste of Processor and Processor groups

What is a Processor? 
Processors are automic elements that can do simple tasks
Each processor in Nifi is unique in its own way 
We have many data source and data sink processors

What is a flow file?
Its the actual data, that is generated by the processor from any data source.
Flowfiles are persisted on the disk and passed by reference. New flowfile will 
be created only if its content is modified but not when its attributes are changed. 

What is a connection?
Processor can be connected to each other via connections. 
Each connection is a queue of flowfile. 

What is a process group? 
Set of processors are combined together to form a process group
Input / Output ports are used to move data between process groups

What is a controller service?
A shared service that can be used by a processor (eg DB connections)

What is relationship? 
Relationships are named to indicate the processing of the Flowfile
Each processor has zero or more relationships defined for it
Once the processor has finished processing a flowfile it will 
transfer the flowfile to one of the relationships


```

## Nifi Processor Types
```xml 
Data injestion processor
Data transformation processor 
Data egress (exiting) processor
Data routing and mediation processor
Database access processor
Attribute extraction processor
System intraction processor
Splitting and aggregation processor
Http and UDP processor 
Amazon webservice processor

```

## Nifi Processor Configuration, Connection & Relationship
```xml 
Nifi follows the philisophy of configuration over coding
All processors have a set of standard configurations and 
unique configurations

Stardard configurations are mostly under settings and scheduling tab.


```

## Processors List 
```xml 

General list of all processors and their details can be found in:
https://nifi.apache.org/components/

When chaining processors backpressure is an important attribute to 
monitor and fine tune

```

## Export And Import Template
```xml 

Export a NiFi Template
----------------------
Select the flow: On the NiFi canvas, select all the components of the flow you 
want to template. You can do this by holding the Shift key and clicking or 
dragging a selection box around them.

Create the template: In the top-left Operate Palette, click the Create Template 
icon (often a template icon with a green plus sign).

Name the template: A dialog box will appear. Give the template a unique name and 
an optional description, then click CREATE.

Download the template (Export): After creation, go to the top-right menu (often a 
hamburger menu or "Manage Templates" icon).

Manage templates: In the Template Management dialog box, find your newly created 
template in the list.

Download as XML: Click the Download icon (often a download arrow symbol) for that 
specific template. This will save the template as a .xml file to your local machine. 

Import a NiFi Template
----------------------
Access the Upload Template dialog: In the top-left Operate Palette of the target NiFi 
instance, click the Upload Template icon (often a template icon with an upward arrow).

Select the file: In the Upload Template dialog, click the file finder icon to browse and 
select the .xml template file you exported earlier from your local machine.

Upload: Click the Upload button in the dialog box to import the template into the NiFi 
instance. A success message will confirm the import. 

Use the Imported Template
-------------------------
Drag the Template icon: From the top toolbar of the NiFi UI, drag the Template icon 
onto the canvas.

Select the template: A dialog box will open, prompting you to select the desired template 
from a dropdown list of all available templates (including the one you just imported).

Add to canvas: Select the template and click ADD to instantiate the flow on your canvas. 

Alternative Method: NiFi Registry
---------------------------------
For managing templates across multiple NiFi instances or for version control, 
a more robust method is using a dedicated Apache NiFi Registry. This allows you to 
version-control process groups and share them seamlessly without manual XML file transfers. 


Sample Nifi Templates can be found in the below link:
https://cwiki.apache.org/confluence/display/nifi/example+dataflow+templates

```

## Generate and Log Processor 
```xml 
What it does 
Generate flowfile is used to generate random data or custom data
Log Attribute processors logs the attributes of the flow file

Check this by importing the template
GenerateAndLog.xml
```


## Replace Text Processor 
```xml 
ReplaceText Processor modifies the content (body) of a FlowFile by finding text matching 
a regular expression or a literal string and replacing it with specified text, or 
by prepending/appending text, effectively changing data as it flows through the system. 
It's crucial for data cleansing, format conversion (like adding leading zeros to dates), 
extracting specific values, or preparing data for downstream processors, but it works on content, 
not attributes. 

Key Functions & Uses
--------------------
Search & Replace: Replaces occurrences of a pattern with new text, using regex capture groups 
(e.g., $1) for dynamic replacements.

Data Transformation: Cleans up data by removing unwanted characters (e.g., units like "cm" from 
numbers) or adding leading zeros to single-digit months/days.

Content Modification: Can prepend or append text to the entire FlowFile or individual lines.

Value Extraction: Used in conjunction with other processors to prepare data for things like 
SQL INSERT statements by replacing placeholders with actual values. 

Important Considerations
------------------------
Evaluation Mode: Can be set to "Line-by-Line" or "Entire text." "Entire text" loads the whole 
file into memory, which can cause OutOfMemoryErrors with large files; "Line-by-Line" is better 
for large datasets.

Not for Attributes: It modifies the FlowFile's content, not its attributes; use the UpdateAttribute 
processor for attributes.

Performance: For complex JSON/Record transformations, ConvertRecord or JoltTransformRecord might be 
more efficient than multiple ReplaceText processors. 

Check this by importing the template
ReplaceText.xml
```

## Extract Text Processor 
```xml 
The Apache NiFi ExtractText Processor uses regular expressions (regex) to pull specific 
text data from a FlowFile's content and assign it to FlowFile attributes for routing or 
further processing, with configurable options for named capture groups to organize results 
into distinct attributes like attribute.1, attribute.2, etc., effectively transforming 
unstructured text into structured metadata. It's a core component for turning text-based 
data into actionable attributes for data pipelines, though for complex document types 
(PDF, Word), you might need custom processors like those powered by Apache Tika. 

Key Functionality
-----------------
Attribute Extraction: Evaluates regex patterns against FlowFile content.

Dynamic Properties: You define custom properties (e.g., my_data), where the property name 
becomes the attribute name and the regex defines what gets captured.

Named Capture Groups: Enabling this creates attributes with names matching your capture groups 
(e.g., my_data.name, my_data.value).

Indexed Capture Groups: Without named groups, results go into attributeName.1, attributeName.2, 
etc., plus the full match in attributeName.0. 

How it Works (Simplified Example)
---------------------------------
Input Data: A FlowFile with content like ID=12345, Name=TestUser.

Configuration (Named Groups):
Add Property: user_id with regex ID=(\d+)
Add Property: user_name with regex Name=(.*)

Output Attributes: user_id=12345, user_name=TestUser. 

Common Use Cases
----------------
Extracting IDs, timestamps, or specific fields from logs or flat files.
Parsing simple structured text into attributes for routing decisions. 

Advanced/Related Processors
---------------------------
ExtractDocumentText: For extracting text from actual binary documents (PDF, DOCX) 
using Apache Tika.

SplitText: Often used before ExtractText to break large files into smaller, line-by-line 
FlowFiles for easier processing. 

Check this by importing the template
ExtractText.xml

This template extracts the content of the comma seperated flow file and assigns it to 
varibale prefixed by csv.1, csv.2 and so on
```

## Expression Language
```xml 
The Apache NiFi Expression Language (EL) is a powerful, domain-specific language used within 
the NiFi application to dynamically reference, compare, and manipulate dataflow attributes, 
variables, and system properties. 

Core Functionality and Purpose
------------------------------
Dynamic Configuration: EL is primarily used in processor properties to make their behavior dynamic, 
allowing components to adapt to the specific data they are processing.

Attribute Manipulation: It provides the ability to access metadata (attributes) associated with a 
FlowFile (the data record within NiFi's flow) and perform various operations like type conversion, 
string manipulation, and mathematical calculations.

Conditional Logic and Routing: Expressions can be used to evaluate conditions (e.g., checking if an 
attribute exists, comparing values) to determine how data should be routed or processed, often in 
components like RouteOnContent or UpdateAttribute.

Accessing System Information: Users can access system properties and environment variables using EL 
for more flexible dataflow configuration. 

Syntax and Structure
--------------------
Expressions are enclosed within the ${ ... } syntax. They often take the form ${attributeName:function()}. 

Chaining Functions: Multiple functions can be chained together, where the output of one function becomes 
the input (subject) of the next function. 
For example: ${filename:toUpper():equals('HELLO.TXT')}.

Data Types: The language supports several data types, including String, Number, Decimal, Date, and Boolean, 
and generally performs automatic type coercion when needed.

Hierarchy: When an expression is evaluated, NiFi searches for the referenced property/variable in a specific 
order:
FlowFile attributes.
Process Group variables (and up the hierarchy to the root process group).
Custom properties file/System environment variables. 

For a detailed list of functions and usage examples, refer to the official Apache NiFi 
Expression Language Guide at the below link: 
https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html

We can read the variables in the flowfile using expression language as below:
{
    "field1": "${csv.1}",
    "field2": "${csv.2}",
    "field3": "${csv.3}",
    "field4": "${csv.4}"
}

Check this by importing the template
JsonConverter.xml

This template extracts the content of the varibale in the flowfile and 
creates a json file as above.


```

## Create Output File
```xml 
The Apache NiFi PutFile processor is a core component used to write the content of a FlowFile 
to the local file system. It is a fundamental building block for data ingest and data flow management 
within a single NiFi instance. 

Key Features and Configuration
------------------------------
Functionality: Transfers the content of an incoming FlowFile to a specified directory on the local disk.

Input/Output: Requires an inbound connection for FlowFiles and transfers successful write operations to a 
success relationship and failures to a failure relationship.

Directory: A mandatory property where the files are written. The path supports the NiFi Expression Language, 
allowing for dynamic directory creation based on FlowFile attributes (e.g., /data/${path}).

Filename: The processor uses the filename attribute of the FlowFile to determine the name of the output file.

Conflict Resolution Strategy: This property determines what happens if a file with the same name already exists 
in the output directory:
replace: Deletes the existing file and writes the new one.
ignore: Leaves the existing file untouched and routes the incoming FlowFile to the success relationship 
(effectively ignoring the new data).
fail: Routes the incoming FlowFile to the failure relationship.

Create Missing Directories: A boolean property that, if set to true (default), automatically creates any 
missing destination directories. If false, the FlowFile is penalized and routed to failure.

Permissions/Owner/Group: Optionally allows setting file system permissions, owner, and group on the output 
file using FlowFile attributes and Expression Language. 

Important Considerations
------------------------
Local File System Only: The PutFile processor can only write to the local file system of the machine where 
the NiFi instance is running. For remote systems (like an SFTP server or cloud storage), you must use specific 
processors such as PutSFTP, PutFTP, or cloud-specific options.

Expression Language: Utilizing the NiFi Expression Language is key to dynamic file naming and pathing, 
ensuring unique files are created or correctly handled (e.g., using a timestamp or original filename attribute).

Permissions: Ensure that the operating system user running the NiFi process has the necessary permissions to 
write to the specified directory. Permission issues are a common cause of the processor routing FlowFiles 
to the failure relationship. 

Check this by importing the template
CreateOutputFile.xml

This template sends the content of the flowfile to an output folder.
The output folder can be configured on the PutFile processor's 
property called Directory, in my case I use 
/Users/balaji/apache-nifi/output


```

## UpdateAttribute Processor 
```xml 
The Apache NiFi UpdateAttribute Processor modifies FlowFile attributes (metadata) using 
user-defined properties, supporting both basic (global) changes and advanced conditional logic 
with the Expression Language (NEL), allowing adding, updating, or deleting attributes based on rules, 
which is crucial for routing, transforming, and enriching data streams. You configure it by adding 
key-value pairs for attributes, using Delete Attributes Expression for removal (regex supported), and 
leveraging the "Advanced" UI for conditional rules based on NEL. 

Key Functions & Usage
---------------------
Add/Modify Attributes: Define new property_name=value pairs or overwrite existing ones.

Conditional Logic: Use the Advanced UI to set rules (conditions + actions) for specific FlowFiles, 
acting like if/else statements.

Attribute Deletion: Use a regular expression in the Delete Attributes Expression property to remove attributes 
by name (e.g., user.* to delete username, userId). 

How It Works
------------
Basic Usage: Add properties directly in the processor configuration for global changes to all FlowFiles.

Advanced Usage (Rules): Click "Advanced" in the configure dialog to create rules with conditions (NEL expressions) 
and actions (add/update/delete).

Expression Language (NEL): Powerful for dynamic values (e.g., ${filename}, ${now()}) and complex comparisons, 
allowing data-driven attribute manipulation. 

Example Use Cases
-----------------
Setting a folder_name attribute based on the file_type.
Adding a timestamp attribute using ${now()}.
Deleting sensitive attributes like password if they match a pattern. 

Important Note
You cannot create an attribute and then modify it within the same UpdateAttribute processor in a single step; 
it must happen sequentially in different processors or steps. 

Insert the updateattribute processor and
Add an attribute called filename with the following expression as its value:
${now():toNumber():format('yyyy-MM-dd-HH-mm-ss')}-${filename}.json
Eg. file name that would be generated:
2026-01-17-13-57-29-2bcabb8e-4649-43a4-bc94-4cff289af4ec.json

Insert this processor between the previously created ReplaceText and PutFile processors

Check this by importing the template
UpdateFileNameAttribute.xml

This template modifies the file name of the flowfile file before it is sent to an output folder.
The output folder is already configured on the PutFile processor's 
property called Directory, in my case as below from the previous example
/Users/balaji/apache-nifi/output

Run it and check the file name created in the output folder with its changed name
```

## Process Group 
```xml 
In Apache NiFi, a Process Group is a mechanism used to logically group a set of components 
(processors, funnels, ports, other process groups) into a single, manageable unit. 
This approach helps in organizing complex dataflows, improving their readability and maintainability. 
The root canvas of a NiFi instance is itself a top-level Process Group. 

Key Features and Functionality
------------------------------
Hierarchy: Process Groups support a hierarchical structure, allowing you to nest groups within 
other groups (similar to a directory structure). This enables dataflow managers (DFMs) to reason 
about the dataflow at varying levels of abstraction.

Encapsulation: Components inside a Process Group operate together as a cohesive unit. You can start, 
stop, enable, or disable all components within a group simultaneously via the group's context menu.

Ports: Data is transferred into and out of a Process Group using Input Ports and Output Ports, 
respectively.
An Input Port within a Process Group receives FlowFiles from an upstream component 
(which can be in the parent group).
An Output Port sends FlowFiles to a downstream component (also typically in the parent group).
Ports provide a clear, defined interface for data exchange with the outside flow.

Remote Process Groups (RPGs): While a standard Process Group organizes flows within a single NiFi 
instance, a Remote Process Group is used to transfer data (via Site-to-Site protocol) to a port on 
a different, remote NiFi instance or cluster.

Configuration and Variables: Process Groups can have their own specific configurations, 
including the assignment of Parameter Contexts, which allow for managing environment-specific variables 
that can be referenced by components within that group.

Reusability and Versioning: You can create a template from a selected Process Group to reuse 
that specific sub-flow in other parts of the current canvas or export it to other NiFi instances. 
Process Groups can also be placed under version control using a NiFi Registry, allowing for tracking 
changes and deploying specific versions across different environments (e.g., staging to production).

Monitoring: The NiFi UI provides monitoring statistics for each Process Group, including the number 
and size of FlowFiles currently in the queues within the group, as well as the data that has passed 
through its ports over a specific time period. 

Common Use Cases
----------------
Logical Organization: Grouping processors that handle a specific data source or perform a particular 
business function (e.g., "Customer Data Ingest," "Elasticsearch Indexing").

Abstraction: Hiding complex, detailed logic within a Process Group so that the top-level flow remains 
clean and easy to understand.

Module Development: Creating reusable, self-contained dataflow modules that can be easily templated 
and shared. 

Using Process Groups:
--------------------
1. Click on the process group and drag it on the canvas
2. Give it a name
3. Drag all components that need to be moved to the process group by holding shift + command key and dragging 
the processes into the process group. You can drag all components by holding the shif key + command and 
selecting all component first before dragging. When we are on top of the process group a blue border appears 
which helps us to drag our processes correctly into the process group. 
4. You can start/stop all processes within process group by selecting the process group and clicking the 
start/stop button.
5. You can enter the process group by double clicking on the process group.
6. To come out of a process group you can right click and click Leave process group to come outside of the group 
or by clicking the navigation links at the bottom of the canvas. 
7. You can duplicate a process group with cnt+C and cnt+V (all the processes and its configuration gets duplicated)
8. You can move a process group by right clicking it and moving to the parent group

9. We divided our processes into 2 process groups, created an input port on the receiving process group 
and output port on the sending process group and connected the 2 processes.

10. Check this by importing the template
ProcessGroupTest.xml

Run it and check the file name created in the output folder with its changed name as before.

```

## Nifi Funnel
```xml
In Apache NiFi, a funnel is a component used to combine data from several incoming 
connections into a single outgoing connection, acting as a junction point to streamline data flows 
and improve canvas organization. 

Key Purposes and Benefits
--------------------------
Flow Consolidation: A funnel allows multiple data streams (FlowFiles) from different processors 
or sources to converge into one combined stream, leading to a single downstream destination.

Organization and Readability: Instead of drawing numerous connections to a single processor, 
a DataFlow Manager (DFM) can route them all to a funnel and then have just one connection from the 
funnel to the next component. This helps keep complex data flows neat and easier to manage.

Simplified Maintenance: If a downstream processor needs to be replaced, only the single connection 
from the funnel needs to be moved to the new processor, rather than manually moving multiple individual 
connections.

Centralized Queue Management: Each connection to the funnel has its own queue, but the data is combined 
into a single logical queue managed by the connection leaving the funnel. This allows for centralized 
management of backpressure and data prioritization settings for all incoming data.

Debugging Aid: Funnels can be used as temporary endpoints during debugging to quickly test intermediate 
results of a flow without needing a final destination processor. 

In essence, a funnel is a simple pass-through component that provides a single point of entry for data 
coming from disparate sources into a unified flow logic. For more details, consult the Apache NiFi User Guide. 

Check this by importing the template
Funnel.xml

Run it to see 2 generate flowflie process sending output to the same funnel that is 
sent to a downstream logattribute processor.

```

## Nifi Instance Monitoring
```xml
Monitoring NiFi involves using its built-in UI for real-time flow status, 
bulletins (errors/warnings), and data provenance, alongside Reporting Tasks 
(like SiteToSiteBulletinReportingTask) to push metrics to external systems, 
and integrating with tools like Prometheus/Grafana for dashboards, or custom 
solutions like MonitoFi, to track key metrics like queue depth, throughput, 
processor health, and FlowFile age for performance tuning and anomaly detection. 

Built-in NiFi Monitoring (UI)
-----------------------------
Processors & Connections: View real-time stats (data processed, throughput), 
status (running/stopped), and queue depth directly on the canvas.

Bulletins: See error/warning notifications as icons on components; access the 
Bulletin Board for detailed, filterable messages.

Data Provenance: Track FlowFile lineage and events for auditing and debugging.

NiFi Summary: Get an overview of all components and their status across the cluster. 
```

## Nifi Registry and Version Control
```xml
Apache NiFi Registry is a complementary application to Apache NiFi that provides a 
central place to store, manage, and version-control shared resources, especially data flows 
(Processor Groups) and extensions, across multiple NiFi or MiNiFi instances, enabling 
collaborative development, CI/CD pipelines, and easier promotion of flows between environments 
(Dev, Test, Prod). It acts like a Git repository for your NiFi flows, allowing you to track changes, 
roll back to previous versions, and manage flow lifecycles efficiently. 

Key Features & Functions:
------------------------
Flow Registry: Stores and manages versioned NiFi data flows (Processor Groups).

Version Control: Enables starting version control on Processor Groups, committing changes, 
and rolling back to earlier versions.

Central Repository: A central location for sharing resources like flows and bundles (extensions).

CI/CD Integration: Facilitates automated deployment of flows from development to production environments, 
managing sensitive data via parameter contexts.

Bucket & Policy Management: Organizes flows into "buckets" (like projects) and manages user access 
and permissions (policies).

NiFi Integration: Seamlessly integrates with NiFi, allowing users to store, retrieve, and upgrade 
flows directly from the NiFi UI. 

How it Works:
-------------
Connect NiFi to Registry: You configure your NiFi instance(s) to point to the NiFi Registry's URL.

Version a Process Group: In NiFi, you right-click a Processor Group and select "Version" > 
"Start version control," linking it to a bucket in the Registry.

Commit Changes: You commit changes (like adding processors or modifying configurations) to the Registry.

Promote Flows: You can then promote validated flows from the Registry to other NiFi instances 
or environments. 

In essence, NiFi Registry brings discipline and lifecycle management to data flow development, 
preventing issues common with manual template management and supporting enterprise-level data 
pipeline operations. 

```

## Nifi Database Connections (MySQL to json file)
```xml
1. Start MySQL database, in my case on docker
docker pull mysql
docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=<my-password> -d mysql

2. Connect to the database using MySQLWorkbench and run the queries given in the 
mysqlsampledatabase.sql file under the 'sample-db' folder.

3. Download the mysql jdbc driver and copy to the nifi's lib folder 

4. Go to Controller Settings -> Management Controller Settings -> Add (+)

5. Search for DBCPConnectionPool add it

6. In the properties of DBCPConnectionPool
Database Connection URL: jdbc:mysql://localhost:3306/classicmodels?autoReconnect=true&useSSL=false
Database Driver Class Name: com.mysql.cj.jdbc.Driver
Datauser: root
Password: <your root password>  #Dont do this on production
Save and Enable

7. Create a new Processor -> QueryDatabaseTableRecord Processor
In the properties add the following:
Database Connection Pooling Service=DBCPConnectionPool
Database Type: MySQL
Table Name: customers
Record Writer: Create a new Record writer -> JsonRecordSetWriter and enable it
Max-value Columns: customerNumber # this will help us not to import the same records again and 
will be imported only when this attribute gets incremented

Finally Apply

8. Create another processor -> PutFile 
In the properties add the following:
<your-file-output-path>

9. Connect both these processors.

10. Start both processors and see the table being queried and 
outputted as json file in the output directory.

11. Check this by importing the below template and running it
MySqlToJson.xml

Note: The state can be reset to query the table from beginning by 
right clicking on the QueryDatabaseTableRecord -> View State -> Clear State

```

## Nifi Database Connections (Read CSV file and insert into MySQL DB)
```xml
1. Start MySQL database, in my case on docker
docker pull mysql
docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=<my-password> -d mysql

2. Connect to the database using MySQLWorkbench and run the query given in the 
logistics.sql file under the 'sample-db' folder.

3. Make sure you have the logistics_shipments_dataset.csv in the dataset folder 

4. Download the mysql jdbc driver from 
and copy to the nifi's lib folder 

5. Go to Controller Settings -> Management Controller Settings -> Add (+)

6. Search for LogisticsConnectionPool add it

7. In the properties of LogisticsConnectionPool
Database Connection URL: jdbc:mysql://localhost:3306/logistics?autoReconnect=true&useSSL=false
Database Driver Class Name: com.mysql.cj.jdbc.Driver
Datauser: root
Password: <your root password>  #Dont do this on production
Save and Enable

8. Also create a CSVReader Controller Service 
Properties:
Schema Access Strategy: Use String Fields from Header

9. Enable both these Controller Services.

10. The processes used are as follows:
GetFile -> SplitText -> ConvertRecord -> ConvertJsonToSQL -> PutSQL 
* Please set all the property values as given in each of the processors 

11. Check this by importing the below template and running it
CsvToMySQL.xml

```
## What Nifi ? Building custom processors
```xml
Check the below link and start building
https://medium.com/@tomerdayan168/build-your-processors-in-nifi-7bb0f217ed75

```

### Reference
```xml
https://www.youtube.com/playlist?list=PL55symSEWBbMBSnNW_Aboh2TpYkNIFMgb
http://www.dvstechnologies.in/apache-nifi/
https://nifi.apache.org/
https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html
https://www.youtube.com/watch?v=OHLYJUOTaYc
https://www.youtube.com/watch?v=8KxcAiNdqvw
```
