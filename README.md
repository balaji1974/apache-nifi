
# Apache Nifi

## What is Apache Nifi
```xml 
Apache NiFi is an open-source, visual data integration platform that automates 
the flow of data between systems, allowing users to design, control, and 
monitor data pipelines through a user-friendly, web-based interface, 
supporting batch and real-time scenarios with features like data provenance, 
security, and scalability. Originally developed by the NSA, it provides a flow-based 
programming model to move, transform, and route data efficiently, acting as a 
powerful tool for data engineering and pipeline automation. 

Key Terms:
Data flow: Moving data from source to destination. Data can be of any format 
like csv, json, xml, http data, image, videoes, telemetry etc
Data Pipeline: Movement and transformation of data content from source to destination 
ETL: Extract, Transform, Load


Key Features
Web UI: A visual interface to build data flows by connecting processors (components).
Data Provenance: Tracks every piece of data (FlowFile) from its origin to its destination, 
showing lineage and history.
Data Flow Automation: Automates data movement, ingestion, enrichment, and transformation 
between diverse sources and destinations.
Flow-Based Programming: Uses a visual, diagrammatic approach to define data pipelines.
Guaranteed Delivery: Configurable to be loss-tolerant or guarantee delivery, with priority queuing.
Extensible: Allows developers to create custom processors and services.
Secure & Scalable: Supports multi-tenant security and clustering for large-scale deployments. 

How it Works (Core Concepts)
FlowFile: The fundamental unit of data in NiFi, containing the actual data (content) 
and metadata (attributes).
Processor: Individual components that perform specific tasks (e.g., fetching data, 
transforming, routing).
Connection: The path data flows along between processors, often with backpressure to 
manage data flow rates.
FlowFile Repository, Content Repository, Provenance Repository: Key components for 
managing FlowFile state, content, and history. 

Use Cases
Collecting data from logs, sensors, and applications.
Real-time data streaming and processing.
Data integration for Big Data systems (e.g., Kafka, Hadoop).
Cybersecurity, observability, and generative AI data pipelines. 

Why choose a framework? (4Vs)
Volume, Velocity, Variety, Veracity (messiness and trustworthiness)

```
![alt text](https://github.com/balaji1974/apache-nifi/blob/main/Nifi-Core.png)

## Installing Nifi on Mac
```xml 
1. Download Nifi
https://nifi.apache.org/download/
Download the binary version
and unzip and move to your the folder of your choice

2. Start Nifi
Go the folder Nifi base folder and run the command
./bin/nifi.sh start
tail -f ./logs/nifi-app.log

3. Set Password
The default user name and password can be viewed on the log file
at /logs/nifi-app.log
Search for the lines Generated Username
In my case I have this:
Generated Username [***username***]
Generated Password [***password***]
* this is generated only once during first run 
and must be changed. 

You can change the password by using the below comm
./bin/nifi.sh set-single-user-credentials USERNAME PASSWORD

Stop Nifi
./bin/nifi.sh stop

and Start it back 
./bin/nifi.sh start


4. Go to Nifi console
https://localhost:8080/nifi
Login using the user id and password

5. Stop Nifi
./bin/nifi.sh stop

```

## First Nifi Process - Copy Files
```xml 
1. Drag a Processer
2. Search for getFile
3. Click on the properties -> Input directory 
4. Enter a source folder path 

5. Drag another Processer
6. Search for putFile
7. Click on the properties -> Directory 
8. Enter a destination folder path 
9. Relationship Tab
10. Failure -> Terminate
11. Success -> Terminate

12. Pull the arrow (connection) from Input Processor to 
Output Processor
13. Start both processes by righ click + start

14. Put any file on the source folder and its 
immediately copied to the destination folder

Import template named GetAndPut.xml into your project 
and drag it to your canvas to see it working

```

## Core Nifi Terminologies
```xml 
What is Nifi? 
Nifi consist of automic elements which can be combibed to groups
to build a data flow
Nifi consiste of Processor and Processor groups

What is a Processor? 
Processors are automic elements that can do simple tasks
Each processor in Nifi is unique in its own way 
We have many data source and data sink processors

What is a flow file?
Its the actual data, that is generated by the processor from any data source.
Flowfiles are persisted on the disk and passed by reference. New flowfile will 
be created only if its content is modified but not when its attributes are changed. 

What is a connection?
Processor can be connected to each other via connections. 
Each connection is a queue of flowfile. 

What is a process group? 
Set of processors are combined together to form a process group
Input / Output ports are used to move data between process groups

What is a controller service?
A shared service that can be used by a processor (eg DB connections)

What is relationship? 
Relationships are named to indicate the processing of the Flowfile
Each processor has zero or more relationships defined for it
Once the processor has finished processing a flowfile it will 
transfer the flowfile to one of the relationships


```

## Nifi Processor Types
```xml 
Data injestion processor
Data transformation processor 
Data egress (exiting) processor
Data routing and mediation processor
Database access processor
Attribute extraction processor
System intraction processor
Splitting and aggregation processor
Http and UDP processor 
Amazon webservice processor

```

## Nifi Processor Configuration, Connection & Relationship
```xml 
Nifi follows the philisophy of configuration over coding
All processors have a set of standard configurations and 
unique configurations

Stardard configurations are mostly under settings and scheduling tab.


```

## Processors List 
```xml 

General list of all processors and their details can be found in:
https://nifi.apache.org/components/

When chaining processors backpressure is an important attribute to 
monitor and fine tune

```

## Export And Import Template
```xml 

Export a NiFi Template
----------------------
Select the flow: On the NiFi canvas, select all the components of the flow you 
want to template. You can do this by holding the Shift key and clicking or 
dragging a selection box around them.

Create the template: In the top-left Operate Palette, click the Create Template 
icon (often a template icon with a green plus sign).

Name the template: A dialog box will appear. Give the template a unique name and 
an optional description, then click CREATE.

Download the template (Export): After creation, go to the top-right menu (often a 
hamburger menu or "Manage Templates" icon).

Manage templates: In the Template Management dialog box, find your newly created 
template in the list.

Download as XML: Click the Download icon (often a download arrow symbol) for that 
specific template. This will save the template as a .xml file to your local machine. 

Import a NiFi Template
----------------------
Access the Upload Template dialog: In the top-left Operate Palette of the target NiFi 
instance, click the Upload Template icon (often a template icon with an upward arrow).

Select the file: In the Upload Template dialog, click the file finder icon to browse and 
select the .xml template file you exported earlier from your local machine.

Upload: Click the Upload button in the dialog box to import the template into the NiFi 
instance. A success message will confirm the import. 

Use the Imported Template
-------------------------
Drag the Template icon: From the top toolbar of the NiFi UI, drag the Template icon 
onto the canvas.

Select the template: A dialog box will open, prompting you to select the desired template 
from a dropdown list of all available templates (including the one you just imported).

Add to canvas: Select the template and click ADD to instantiate the flow on your canvas. 

Alternative Method: NiFi Registry
---------------------------------
For managing templates across multiple NiFi instances or for version control, 
a more robust method is using a dedicated Apache NiFi Registry. This allows you to 
version-control process groups and share them seamlessly without manual XML file transfers. 

```

## Generate and Log Processor 
```xml 
What it does 
Generate flowfile is used to generate random data or custom data
Log Attribute processors logs the attributes of the flow file

Check this by importing the template
GenerateAndLog.xml
```


## Replace Text Processor 
```xml 
ReplaceText Processor modifies the content (body) of a FlowFile by finding text matching 
a regular expression or a literal string and replacing it with specified text, or 
by prepending/appending text, effectively changing data as it flows through the system. 
It's crucial for data cleansing, format conversion (like adding leading zeros to dates), 
extracting specific values, or preparing data for downstream processors, but it works on content, 
not attributes. 

Key Functions & Uses
--------------------
Search & Replace: Replaces occurrences of a pattern with new text, using regex capture groups 
(e.g., $1) for dynamic replacements.

Data Transformation: Cleans up data by removing unwanted characters (e.g., units like "cm" from 
numbers) or adding leading zeros to single-digit months/days.

Content Modification: Can prepend or append text to the entire FlowFile or individual lines.

Value Extraction: Used in conjunction with other processors to prepare data for things like 
SQL INSERT statements by replacing placeholders with actual values. 

Important Considerations
------------------------
Evaluation Mode: Can be set to "Line-by-Line" or "Entire text." "Entire text" loads the whole 
file into memory, which can cause OutOfMemoryErrors with large files; "Line-by-Line" is better 
for large datasets.

Not for Attributes: It modifies the FlowFile's content, not its attributes; use the UpdateAttribute 
processor for attributes.

Performance: For complex JSON/Record transformations, ConvertRecord or JoltTransformRecord might be 
more efficient than multiple ReplaceText processors. 

Check this by importing the template
ReplaceText.xml
```

## Extract Text Processor 
```xml 
The Apache NiFi ExtractText Processor uses regular expressions (regex) to pull specific 
text data from a FlowFile's content and assign it to FlowFile attributes for routing or 
further processing, with configurable options for named capture groups to organize results 
into distinct attributes like attribute.1, attribute.2, etc., effectively transforming 
unstructured text into structured metadata. It's a core component for turning text-based 
data into actionable attributes for data pipelines, though for complex document types 
(PDF, Word), you might need custom processors like those powered by Apache Tika. 

Key Functionality
-----------------
Attribute Extraction: Evaluates regex patterns against FlowFile content.

Dynamic Properties: You define custom properties (e.g., my_data), where the property name 
becomes the attribute name and the regex defines what gets captured.

Named Capture Groups: Enabling this creates attributes with names matching your capture groups 
(e.g., my_data.name, my_data.value).

Indexed Capture Groups: Without named groups, results go into attributeName.1, attributeName.2, 
etc., plus the full match in attributeName.0. 

How it Works (Simplified Example)
---------------------------------
Input Data: A FlowFile with content like ID=12345, Name=TestUser.

Configuration (Named Groups):
Add Property: user_id with regex ID=(\d+)
Add Property: user_name with regex Name=(.*)

Output Attributes: user_id=12345, user_name=TestUser. 

Common Use Cases
----------------
Extracting IDs, timestamps, or specific fields from logs or flat files.
Parsing simple structured text into attributes for routing decisions. 

Advanced/Related Processors
---------------------------
ExtractDocumentText: For extracting text from actual binary documents (PDF, DOCX) 
using Apache Tika.

SplitText: Often used before ExtractText to break large files into smaller, line-by-line 
FlowFiles for easier processing. 

Check this by importing the template
ExtractText.xml

This template extracts the content of the comma seperated flow file and assigns it to 
varibale prefixed by csv.1, csv.2 and so on
```

## Expression Language
```xml 
The Apache NiFi Expression Language (EL) is a powerful, domain-specific language used within 
the NiFi application to dynamically reference, compare, and manipulate dataflow attributes, 
variables, and system properties. 

Core Functionality and Purpose
------------------------------
Dynamic Configuration: EL is primarily used in processor properties to make their behavior dynamic, 
allowing components to adapt to the specific data they are processing.

Attribute Manipulation: It provides the ability to access metadata (attributes) associated with a 
FlowFile (the data record within NiFi's flow) and perform various operations like type conversion, 
string manipulation, and mathematical calculations.

Conditional Logic and Routing: Expressions can be used to evaluate conditions (e.g., checking if an 
attribute exists, comparing values) to determine how data should be routed or processed, often in 
components like RouteOnContent or UpdateAttribute.

Accessing System Information: Users can access system properties and environment variables using EL 
for more flexible dataflow configuration. 

Syntax and Structure
--------------------
Expressions are enclosed within the ${ ... } syntax. They often take the form ${attributeName:function()}. 

Chaining Functions: Multiple functions can be chained together, where the output of one function becomes 
the input (subject) of the next function. 
For example: ${filename:toUpper():equals('HELLO.TXT')}.

Data Types: The language supports several data types, including String, Number, Decimal, Date, and Boolean, 
and generally performs automatic type coercion when needed.

Hierarchy: When an expression is evaluated, NiFi searches for the referenced property/variable in a specific 
order:
FlowFile attributes.
Process Group variables (and up the hierarchy to the root process group).
Custom properties file/System environment variables. 

For a detailed list of functions and usage examples, refer to the official Apache NiFi 
Expression Language Guide at the below link: 
https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html

We can read the variables in the flowfile using expression language as below:
{
    "field1": "${csv.1}",
    "field2": "${csv.2}",
    "field3": "${csv.3}",
    "field4": "${csv.4}"
}

Check this by importing the template
JsonConverter.xml

This template extracts the content of the varibale in the flowfile and 
creates a json file as above.


```

### Reference
```xml
https://www.youtube.com/playlist?list=PL55symSEWBbMBSnNW_Aboh2TpYkNIFMgb
http://www.dvstechnologies.in/apache-nifi/
https://nifi.apache.org/
https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html
```
